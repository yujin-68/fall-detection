{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c365730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 43.0ms\n",
      "Speed: 179.3ms preprocess, 43.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 0 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Speed: 1.1ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 1 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 42.3ms\n",
      "Speed: 1.0ms preprocess, 42.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 2 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.4ms\n",
      "Speed: 1.1ms preprocess, 40.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 3 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 41.8ms\n",
      "Speed: 1.0ms preprocess, 41.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 4 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 42.9ms\n",
      "Speed: 1.1ms preprocess, 42.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 5 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 43.6ms\n",
      "Speed: 1.1ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 6 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 39.9ms\n",
      "Speed: 1.0ms preprocess, 39.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 7 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 45.6ms\n",
      "Speed: 1.0ms preprocess, 45.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 8 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.8ms\n",
      "Speed: 1.3ms preprocess, 40.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 9 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 39.9ms\n",
      "Speed: 1.3ms preprocess, 39.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 10 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 42.1ms\n",
      "Speed: 1.1ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 11 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.7ms\n",
      "Speed: 1.2ms preprocess, 40.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 12 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 48.1ms\n",
      "Speed: 1.0ms preprocess, 48.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 13 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 53.0ms\n",
      "Speed: 1.6ms preprocess, 53.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 14 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 63.5ms\n",
      "Speed: 1.5ms preprocess, 63.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 15 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 59.7ms\n",
      "Speed: 1.6ms preprocess, 59.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 16 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 61.8ms\n",
      "Speed: 1.7ms preprocess, 61.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 17 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 45.3ms\n",
      "Speed: 1.1ms preprocess, 45.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 18 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 53.7ms\n",
      "Speed: 1.1ms preprocess, 53.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 19 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 42.7ms\n",
      "Speed: 1.0ms preprocess, 42.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 20 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 42.6ms\n",
      "Speed: 1.1ms preprocess, 42.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 21 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 39.3ms\n",
      "Speed: 1.1ms preprocess, 39.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 22 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.0ms\n",
      "Speed: 1.4ms preprocess, 40.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 23 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 38.9ms\n",
      "Speed: 1.2ms preprocess, 38.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 24 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 42.1ms\n",
      "Speed: 1.2ms preprocess, 42.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 25 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Speed: 1.2ms preprocess, 39.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 26 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 39.4ms\n",
      "Speed: 1.1ms preprocess, 39.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 27 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 39.5ms\n",
      "Speed: 1.0ms preprocess, 39.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 28 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 41.7ms\n",
      "Speed: 1.1ms preprocess, 41.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 29 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 38.2ms\n",
      "Speed: 1.0ms preprocess, 38.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 30 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 38.9ms\n",
      "Speed: 1.0ms preprocess, 38.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 31 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.7ms\n",
      "Speed: 1.1ms preprocess, 40.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 32 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 42.3ms\n",
      "Speed: 1.1ms preprocess, 42.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 33 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 38.7ms\n",
      "Speed: 1.2ms preprocess, 38.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 34 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 45.0ms\n",
      "Speed: 1.3ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 35 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.0ms\n",
      "Speed: 0.9ms preprocess, 40.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 36 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.1ms\n",
      "Speed: 1.1ms preprocess, 40.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 37 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 38.5ms\n",
      "Speed: 1.0ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 38 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 41.2ms\n",
      "Speed: 1.0ms preprocess, 41.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 39 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.1ms\n",
      "Speed: 1.0ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 40 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 51.7ms\n",
      "Speed: 1.5ms preprocess, 51.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 41 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 38.9ms\n",
      "Speed: 0.9ms preprocess, 38.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 42 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 39.9ms\n",
      "Speed: 1.0ms preprocess, 39.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 43 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.3ms\n",
      "Speed: 1.1ms preprocess, 40.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 44 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 45 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 39.4ms\n",
      "Speed: 0.9ms preprocess, 39.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 46 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.6ms\n",
      "Speed: 1.0ms preprocess, 40.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 47 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 38.6ms\n",
      "Speed: 0.9ms preprocess, 38.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 48 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 39.1ms\n",
      "Speed: 1.1ms preprocess, 39.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 49 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 41.5ms\n",
      "Speed: 1.2ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 50 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.8ms\n",
      "Speed: 1.2ms preprocess, 40.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 51 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 42.4ms\n",
      "Speed: 1.1ms preprocess, 42.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 52 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 39.2ms\n",
      "Speed: 1.0ms preprocess, 39.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 53 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 42.3ms\n",
      "Speed: 1.4ms preprocess, 42.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 54 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.9ms\n",
      "Speed: 1.1ms preprocess, 40.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 55 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 56 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 43.6ms\n",
      "Speed: 1.4ms preprocess, 43.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 57 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.4ms\n",
      "Speed: 1.0ms preprocess, 40.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 58 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.4ms\n",
      "Speed: 1.0ms preprocess, 40.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 59 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.1ms\n",
      "Speed: 1.0ms preprocess, 40.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 60 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 42.8ms\n",
      "Speed: 1.0ms preprocess, 42.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 61 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 39.8ms\n",
      "Speed: 1.0ms preprocess, 39.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 62 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 39.6ms\n",
      "Speed: 1.1ms preprocess, 39.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 63 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 41.2ms\n",
      "Speed: 1.0ms preprocess, 41.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 64 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 43.8ms\n",
      "Speed: 1.1ms preprocess, 43.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 65 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 38.9ms\n",
      "Speed: 1.2ms preprocess, 38.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 66 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 58.6ms\n",
      "Speed: 1.0ms preprocess, 58.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 67 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 41.6ms\n",
      "Speed: 1.4ms preprocess, 41.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 68 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 41.8ms\n",
      "Speed: 1.1ms preprocess, 41.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 69 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 39.7ms\n",
      "Speed: 1.0ms preprocess, 39.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 70 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 39.9ms\n",
      "Speed: 1.1ms preprocess, 39.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 71 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 41.0ms\n",
      "Speed: 1.2ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 72 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 40.3ms\n",
      "Speed: 1.2ms preprocess, 40.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 73 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 39.2ms\n",
      "Speed: 1.1ms preprocess, 39.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 74 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 42.8ms\n",
      "Speed: 1.0ms preprocess, 42.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 75 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 38.7ms\n",
      "Speed: 1.1ms preprocess, 38.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 76 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 39.2ms\n",
      "Speed: 1.2ms preprocess, 39.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 77 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 38.9ms\n",
      "Speed: 1.0ms preprocess, 38.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 78 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Speed: 0.9ms preprocess, 37.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 79 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.1ms\n",
      "Speed: 0.9ms preprocess, 40.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 80 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 41.7ms\n",
      "Speed: 1.0ms preprocess, 41.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 81 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 82 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 42.6ms\n",
      "Speed: 0.9ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 83 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 surfboard, 40.8ms\n",
      "Speed: 1.3ms preprocess, 40.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 84 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.1ms\n",
      "Speed: 1.0ms preprocess, 40.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 85 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 38.9ms\n",
      "Speed: 1.0ms preprocess, 38.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 86 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 41.4ms\n",
      "Speed: 1.1ms preprocess, 41.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 87 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 38.4ms\n",
      "Speed: 1.0ms preprocess, 38.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 88 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 surfboard, 40.9ms\n",
      "Speed: 1.1ms preprocess, 40.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 89 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 surfboard, 39.6ms\n",
      "Speed: 1.2ms preprocess, 39.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 90 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 surfboard, 40.4ms\n",
      "Speed: 1.2ms preprocess, 40.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 91 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 surfboard, 41.0ms\n",
      "Speed: 1.4ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 92 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 surfboard, 56.4ms\n",
      "Speed: 1.1ms preprocess, 56.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 93 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.3ms\n",
      "Speed: 1.0ms preprocess, 40.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 94 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.5ms\n",
      "Speed: 1.1ms preprocess, 40.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 95 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.0ms\n",
      "Speed: 1.0ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 96 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 39.1ms\n",
      "Speed: 1.0ms preprocess, 39.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 97 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.7ms\n",
      "Speed: 1.1ms preprocess, 40.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 98 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 42.2ms\n",
      "Speed: 1.1ms preprocess, 42.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 99 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 41.8ms\n",
      "Speed: 1.0ms preprocess, 41.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 100 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.2ms\n",
      "Speed: 0.9ms preprocess, 40.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 101 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.8ms\n",
      "Speed: 1.0ms preprocess, 40.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 102 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 clock, 42.2ms\n",
      "Speed: 1.0ms preprocess, 42.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 103 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 clock, 39.5ms\n",
      "Speed: 1.0ms preprocess, 39.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 104 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 40.0ms\n",
      "Speed: 1.1ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 105 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 106 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 40.4ms\n",
      "Speed: 1.0ms preprocess, 40.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 107 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 40.2ms\n",
      "Speed: 0.9ms preprocess, 40.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 108 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 1 clock, 39.7ms\n",
      "Speed: 0.9ms preprocess, 39.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 109 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 2 chairs, 1 clock, 38.7ms\n",
      "Speed: 1.0ms preprocess, 38.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 110 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 2 chairs, 37.7ms\n",
      "Speed: 0.9ms preprocess, 37.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 111 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 39.2ms\n",
      "Speed: 1.1ms preprocess, 39.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 112 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 40.0ms\n",
      "Speed: 0.9ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 113 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 39.3ms\n",
      "Speed: 0.9ms preprocess, 39.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 114 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 45.8ms\n",
      "Speed: 1.0ms preprocess, 45.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 115 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 40.3ms\n",
      "Speed: 1.1ms preprocess, 40.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 116 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 bird, 1 chair, 41.9ms\n",
      "Speed: 1.0ms preprocess, 41.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 117 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 40.4ms\n",
      "Speed: 1.0ms preprocess, 40.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 118 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 119 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 43.6ms\n",
      "Speed: 1.3ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 120 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 1 clock, 42.2ms\n",
      "Speed: 1.2ms preprocess, 42.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 121 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 41.7ms\n",
      "Speed: 0.9ms preprocess, 41.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 122 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 58.2ms\n",
      "Speed: 1.0ms preprocess, 58.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 123 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 2 chairs, 1 clock, 48.4ms\n",
      "Speed: 1.0ms preprocess, 48.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 124 - Status: Lying\n",
      "\n",
      "0: 384x640 1 bird, 1 chair, 1 clock, 43.1ms\n",
      "Speed: 1.2ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 125 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 clock, 43.5ms\n",
      "Speed: 1.1ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 126 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 40.4ms\n",
      "Speed: 1.0ms preprocess, 40.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 127 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 38.5ms\n",
      "Speed: 0.9ms preprocess, 38.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 128 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 40.6ms\n",
      "Speed: 1.0ms preprocess, 40.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 129 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 39.7ms\n",
      "Speed: 0.9ms preprocess, 39.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 130 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 1 clock, 41.2ms\n",
      "Speed: 1.0ms preprocess, 41.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 131 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 1 clock, 39.9ms\n",
      "Speed: 1.1ms preprocess, 39.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 132 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 42.3ms\n",
      "Speed: 1.2ms preprocess, 42.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 133 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 clock, 41.1ms\n",
      "Speed: 1.1ms preprocess, 41.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 134 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 1 clock, 40.0ms\n",
      "Speed: 1.0ms preprocess, 40.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 135 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 1 clock, 40.9ms\n",
      "Speed: 1.0ms preprocess, 40.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 136 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 clock, 40.6ms\n",
      "Speed: 1.0ms preprocess, 40.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 137 - Status: Lying\n",
      "\n",
      "0: 384x640 1 chair, 1 clock, 42.9ms\n",
      "Speed: 1.1ms preprocess, 42.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 138 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 39.5ms\n",
      "Speed: 1.0ms preprocess, 39.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 139 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 1 clock, 39.2ms\n",
      "Speed: 1.1ms preprocess, 39.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 140 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 40.0ms\n",
      "Speed: 1.0ms preprocess, 40.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 141 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 1 clock, 39.5ms\n",
      "Speed: 0.9ms preprocess, 39.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 142 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 1 clock, 39.6ms\n",
      "Speed: 0.9ms preprocess, 39.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 143 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 39.1ms\n",
      "Speed: 1.1ms preprocess, 39.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 144 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 41.8ms\n",
      "Speed: 1.0ms preprocess, 41.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 145 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 38.9ms\n",
      "Speed: 1.0ms preprocess, 38.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 146 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 41.6ms\n",
      "Speed: 0.9ms preprocess, 41.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 147 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 40.3ms\n",
      "Speed: 0.9ms preprocess, 40.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 148 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 39.6ms\n",
      "Speed: 1.0ms preprocess, 39.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 149 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 1 clock, 40.7ms\n",
      "Speed: 1.1ms preprocess, 40.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 150 - Status: Lying\n",
      "\n",
      "0: 384x640 1 chair, 42.1ms\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 151 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 1 clock, 40.4ms\n",
      "Speed: 1.0ms preprocess, 40.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 152 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 53.3ms\n",
      "Speed: 1.0ms preprocess, 53.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 153 - Status: Lying\n",
      "\n",
      "0: 384x640 1 chair, 1 clock, 42.7ms\n",
      "Speed: 1.0ms preprocess, 42.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 154 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 41.4ms\n",
      "Speed: 1.0ms preprocess, 41.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 155 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 39.3ms\n",
      "Speed: 1.0ms preprocess, 39.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 156 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 1 clock, 40.7ms\n",
      "Speed: 1.1ms preprocess, 40.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 157 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 1 clock, 40.1ms\n",
      "Speed: 1.0ms preprocess, 40.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 158 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 40.0ms\n",
      "Speed: 0.9ms preprocess, 40.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 159 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 38.9ms\n",
      "Speed: 0.9ms preprocess, 38.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 160 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 161 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 41.1ms\n",
      "Speed: 1.0ms preprocess, 41.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 162 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 1 clock, 40.9ms\n",
      "Speed: 1.3ms preprocess, 40.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 163 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 39.9ms\n",
      "Speed: 0.9ms preprocess, 39.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 164 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 1 clock, 38.1ms\n",
      "Speed: 0.9ms preprocess, 38.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 165 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 1 clock, 38.4ms\n",
      "Speed: 0.9ms preprocess, 38.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 166 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 1 clock, 41.7ms\n",
      "Speed: 1.3ms preprocess, 41.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 167 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 39.7ms\n",
      "Speed: 0.9ms preprocess, 39.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 168 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 1 clock, 40.5ms\n",
      "Speed: 0.9ms preprocess, 40.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 169 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 1 clock, 39.8ms\n",
      "Speed: 0.9ms preprocess, 39.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 170 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 1 clock, 41.7ms\n",
      "Speed: 0.9ms preprocess, 41.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 171 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 46.5ms\n",
      "Speed: 1.4ms preprocess, 46.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 172 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 39.7ms\n",
      "Speed: 0.9ms preprocess, 39.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 173 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 41.1ms\n",
      "Speed: 1.0ms preprocess, 41.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 174 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 39.9ms\n",
      "Speed: 1.1ms preprocess, 39.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 175 - Status: Lying\n",
      "\n",
      "0: 384x640 1 chair, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 176 - Status: Lying\n",
      "\n",
      "0: 384x640 1 chair, 40.8ms\n",
      "Speed: 0.9ms preprocess, 40.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 177 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 40.0ms\n",
      "Speed: 0.9ms preprocess, 40.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 178 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 39.0ms\n",
      "Speed: 0.9ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 179 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 46.5ms\n",
      "Speed: 1.1ms preprocess, 46.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 180 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 50.7ms\n",
      "Speed: 1.9ms preprocess, 50.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 181 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 1 clock, 39.6ms\n",
      "Speed: 1.0ms preprocess, 39.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 182 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 40.3ms\n",
      "Speed: 0.9ms preprocess, 40.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 183 - Status: Lying\n",
      "\n",
      "0: 384x640 1 chair, 42.8ms\n",
      "Speed: 0.9ms preprocess, 42.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 184 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 44.7ms\n",
      "Speed: 1.0ms preprocess, 44.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 185 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 42.1ms\n",
      "Speed: 1.1ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 186 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 39.5ms\n",
      "Speed: 0.9ms preprocess, 39.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 187 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 39.5ms\n",
      "Speed: 0.9ms preprocess, 39.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 188 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 38.6ms\n",
      "Speed: 1.0ms preprocess, 38.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 189 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 1 clock, 38.2ms\n",
      "Speed: 0.9ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 190 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 1 clock, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 191 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 39.6ms\n",
      "Speed: 0.9ms preprocess, 39.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 192 - Status: Lying\n",
      "\n",
      "0: 384x640 1 chair, 1 clock, 41.6ms\n",
      "Speed: 1.1ms preprocess, 41.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 193 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 38.2ms\n",
      "Speed: 0.9ms preprocess, 38.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 194 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 38.4ms\n",
      "Speed: 0.9ms preprocess, 38.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 195 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 1 clock, 42.6ms\n",
      "Speed: 1.2ms preprocess, 42.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 196 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 1 clock, 38.7ms\n",
      "Speed: 0.9ms preprocess, 38.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 197 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 41.0ms\n",
      "Speed: 0.9ms preprocess, 41.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 198 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 1 clock, 40.2ms\n",
      "Speed: 0.9ms preprocess, 40.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 199 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 39.4ms\n",
      "Speed: 0.9ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 200 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 1 clock, 39.9ms\n",
      "Speed: 0.9ms preprocess, 39.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 201 - Status: Lying\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 42.4ms\n",
      "Speed: 1.1ms preprocess, 42.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 202 - Status: Lying\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "# Jupyter 환경에서 src 폴더의 모듈을 가져오기 위해 경로를 추가합니다.\n",
    "import sys\n",
    "# 경로 추가에 필요한 os 모듈을 가져옵니다.\n",
    "import os\n",
    "\n",
    "# 현재 노트북 파일의 상위 폴더(FALL-DETECTION)의 경로를 sys.path에 추가합니다.\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# 이미지 및 비디오 처리를 위해 cv2(OpenCV)를 가져옵니다.\n",
    "import cv2\n",
    "# 시간 관련 기능을 위해 time 모듈을 가져옵니다.\n",
    "import time\n",
    "# numpy를 가져와서 수치 연산에 사용합니다.\n",
    "import numpy as np\n",
    "\n",
    "# src 폴더의 핵심 클래스들을 가져옵니다.\n",
    "from src.detector import YoloDetector\n",
    "from src.pose_estimator import PoseEstimator\n",
    "from src.fall_logic import FallDetectorLogic\n",
    "\n",
    "\n",
    "# 1. 초기화 (Initialization)\n",
    "# ---\n",
    "\n",
    "# YOLO, MediaPipe, 낙상 로직 클래스의 인스턴스를 생성합니다.\n",
    "yolo_detector = YoloDetector()\n",
    "pose_estimator = PoseEstimator()\n",
    "fall_logic = FallDetectorLogic()\n",
    "\n",
    "# 비디오 파일 경로 설정. (FALL-DETECTION/data/videos/fall.mp4)\n",
    "video_path = os.path.join(os.path.abspath(os.path.join(os.getcwd(), '..')), 'data', 'videos', 'fall.mp4')\n",
    "\n",
    "# OpenCV를 사용하여 비디오 파일을 엽니다.\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 비디오 파일이 성공적으로 열렸는지 확인합니다.\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video file at {video_path}\")\n",
    "    # 노트북 실행을 중단합니다.\n",
    "    raise FileNotFoundError(\"Video file not found or could not be opened.\")\n",
    "\n",
    "# 프레임 수를 제한하여 디버깅 속도를 높입니다. (예: 50 프레임만 처리)\n",
    "# FRAME_LIMIT = 240\n",
    "frame_count = 0\n",
    "\n",
    "# 낙상 지표 기록을 위한 리스트를 초기화합니다.\n",
    "# 시각화 셀에서 그래프를 그리는 데 사용됩니다.\n",
    "status_history = []\n",
    "\n",
    "\n",
    "# 2. 메인 처리 루프 (Main Processing Loop)\n",
    "# ---\n",
    "\n",
    "# 비디오가 열려 있고 프레임 제한을 넘지 않은 동안 반복합니다.\n",
    "while cap.isOpened():\n",
    "    # 비디오에서 다음 프레임을 읽습니다.\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # 프레임을 제대로 읽지 못했다면 루프를 종료합니다.\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 현재 시간을 기록합니다.\n",
    "    current_time = time.time()\n",
    "    \n",
    "    # 1. YOLO를 사용하여 사람을 감지하고 바운딩 박스를 얻습니다.\n",
    "    detections = yolo_detector.detect_person(frame)\n",
    "\n",
    "    # 감지된 각 사람에 대해 반복합니다.\n",
    "    for person_data in detections:\n",
    "        bbox = person_data['bbox']\n",
    "        # 디버깅 목적으로 임시 track_id 1을 사용합니다.\n",
    "        track_id = 1 \n",
    "\n",
    "        # 2. MediaPipe를 사용하여 뼈대 랜드마크를 추정하고 프레임에 그립니다.\n",
    "        pose_landmarks = pose_estimator.estimate_pose(frame)\n",
    "        \n",
    "        # 3. 낙상 로직을 실행하여 상태를 판단합니다.\n",
    "        person_status = fall_logic.process_detection(track_id, bbox, current_time)\n",
    "\n",
    "        # 상태 기록 (디버깅 그래프 생성을 위해)\n",
    "        status_history.append({'frame': frame_count, 'status': person_status})\n",
    "\n",
    "        # 4. 시각화 및 결과 출력\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        color = (0, 255, 0)\n",
    "        if 'Fall' in person_status or 'Lying' in person_status:\n",
    "            color = (0, 0, 255) # 낙상/누움 상태는 빨간색\n",
    "\n",
    "        # 바운딩 박스를 프레임에 그립니다.\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        # 상태 텍스트를 프레임에 표시합니다.\n",
    "        cv2.putText(frame, person_status, (x1, y1 - 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "        \n",
    "    # 처리된 프레임을 시각적으로 확인합니다.\n",
    "    # if frame_count % 10 == 0:\n",
    "    print(f\"Processing frame: {frame_count} - Status: {person_status}\")\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# 3. 종료 (Finalization)\n",
    "# ---\n",
    "\n",
    "# 비디오 캡처 자원을 해제합니다.\n",
    "cap.release()\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da14a397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Status Log (First 10 entries) ---\n",
      "   frame    status\n",
      "0      0  Standing\n",
      "1      1  Standing\n",
      "2      2  Standing\n",
      "3      3  Standing\n",
      "4      4  Standing\n",
      "5      5  Standing\n",
      "6      6  Standing\n",
      "7      7  Standing\n",
      "8      8  Standing\n",
      "9      9  Standing\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 기록된 상태 히스토리를 DataFrame으로 변환합니다.\n",
    "df = pd.DataFrame(status_history)\n",
    "\n",
    "# 시간 경과에 따른 상태 변화를 시각화합니다.\n",
    "plt.figure(figsize=(15, 6))\n",
    "# 상태를 시각화하기 위해 각 상태에 숫자 값을 부여합니다.\n",
    "status_map = {'Standing': 0, 'Sitting': 1, 'Potential Fall': 2, 'Lying': 3, 'Fall Detected!': 4}\n",
    "df['status_code'] = df['status'].map(status_map)\n",
    "\n",
    "# 상태 코드 변화를 프레임 번호에 따라 그래프로 표시합니다.\n",
    "plt.plot(df['frame'], df['status_code'], marker='o', linestyle='-')\n",
    "plt.yticks(list(status_map.values()), list(status_map.keys()))\n",
    "plt.xlabel(\"Frame Number\")\n",
    "plt.ylabel(\"Fall Detection Status\")\n",
    "plt.title(\"Algorithm Status Change Over Time\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 최종적으로 기록된 상태 변화를 출력합니다.\n",
    "print(\"\\n--- Final Status Log (First 10 entries) ---\")\n",
    "print(df[['frame', 'status']].head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aipj_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
