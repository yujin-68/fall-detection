{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c365730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 traffic light, 56.7ms\n",
      "Speed: 215.7ms preprocess, 56.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 0 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 42.2ms\n",
      "Speed: 2.0ms preprocess, 42.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 1 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 41.9ms\n",
      "Speed: 1.1ms preprocess, 41.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 2 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 45.4ms\n",
      "Speed: 2.1ms preprocess, 45.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 3 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 1 traffic light, 46.5ms\n",
      "Speed: 1.2ms preprocess, 46.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 4 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 39.6ms\n",
      "Speed: 1.1ms preprocess, 39.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 5 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 44.1ms\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 6 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 46.2ms\n",
      "Speed: 1.2ms preprocess, 46.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 7 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 42.5ms\n",
      "Speed: 1.3ms preprocess, 42.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 8 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.6ms\n",
      "Speed: 1.2ms preprocess, 40.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 9 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 44.2ms\n",
      "Speed: 1.0ms preprocess, 44.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 10 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 43.6ms\n",
      "Speed: 1.1ms preprocess, 43.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 11 - Status: Standing\n",
      "\n",
      "0: 384x640 3 persons, 43.7ms\n",
      "Speed: 1.2ms preprocess, 43.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 12 - Status: Standing\n",
      "\n",
      "0: 384x640 3 persons, 41.0ms\n",
      "Speed: 1.1ms preprocess, 41.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 13 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 42.4ms\n",
      "Speed: 1.2ms preprocess, 42.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 14 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 41.5ms\n",
      "Speed: 1.3ms preprocess, 41.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 15 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.8ms\n",
      "Speed: 1.4ms preprocess, 40.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 16 - Status: Standing\n",
      "\n",
      "0: 384x640 3 persons, 1 traffic light, 40.0ms\n",
      "Speed: 1.0ms preprocess, 40.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 17 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 41.3ms\n",
      "Speed: 1.2ms preprocess, 41.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 18 - Status: Standing\n",
      "\n",
      "0: 384x640 3 persons, 44.5ms\n",
      "Speed: 1.1ms preprocess, 44.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 19 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 41.6ms\n",
      "Speed: 1.1ms preprocess, 41.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 20 - Status: Standing\n",
      "\n",
      "0: 384x640 3 persons, 1 traffic light, 43.7ms\n",
      "Speed: 1.1ms preprocess, 43.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 21 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 38.5ms\n",
      "Speed: 1.2ms preprocess, 38.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 22 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 41.3ms\n",
      "Speed: 1.3ms preprocess, 41.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 23 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 39.7ms\n",
      "Speed: 1.2ms preprocess, 39.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 24 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 40.5ms\n",
      "Speed: 1.1ms preprocess, 40.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 25 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 46.9ms\n",
      "Speed: 1.1ms preprocess, 46.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 26 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 48.7ms\n",
      "Speed: 1.5ms preprocess, 48.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 27 - Status: Standing\n",
      "\n",
      "0: 384x640 4 persons, 45.9ms\n",
      "Speed: 1.4ms preprocess, 45.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 28 - Status: Standing\n",
      "\n",
      "0: 384x640 3 persons, 42.4ms\n",
      "Speed: 1.3ms preprocess, 42.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 29 - Status: Standing\n",
      "\n",
      "0: 384x640 3 persons, 1 traffic light, 41.6ms\n",
      "Speed: 1.2ms preprocess, 41.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 30 - Status: Standing\n",
      "\n",
      "0: 384x640 3 persons, 1 traffic light, 41.4ms\n",
      "Speed: 1.0ms preprocess, 41.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 31 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 44.4ms\n",
      "Speed: 1.4ms preprocess, 44.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 32 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 1 traffic light, 46.0ms\n",
      "Speed: 1.3ms preprocess, 46.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 33 - Status: Standing\n",
      "\n",
      "0: 384x640 3 persons, 47.1ms\n",
      "Speed: 1.1ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 34 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 44.6ms\n",
      "Speed: 1.4ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 35 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 42.7ms\n",
      "Speed: 1.2ms preprocess, 42.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 36 - Status: Standing\n",
      "\n",
      "0: 384x640 5 persons, 47.0ms\n",
      "Speed: 1.3ms preprocess, 47.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 37 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 46.9ms\n",
      "Speed: 1.1ms preprocess, 46.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 38 - Status: Standing\n",
      "\n",
      "0: 384x640 3 persons, 49.9ms\n",
      "Speed: 1.4ms preprocess, 49.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 39 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 47.9ms\n",
      "Speed: 1.2ms preprocess, 47.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 40 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 44.2ms\n",
      "Speed: 1.2ms preprocess, 44.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 41 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 42.6ms\n",
      "Speed: 1.3ms preprocess, 42.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 42 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 43.0ms\n",
      "Speed: 1.4ms preprocess, 43.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 43 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 42.2ms\n",
      "Speed: 1.4ms preprocess, 42.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 44 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 44.0ms\n",
      "Speed: 1.4ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 45 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 43.0ms\n",
      "Speed: 1.1ms preprocess, 43.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 46 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 42.9ms\n",
      "Speed: 1.3ms preprocess, 42.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 47 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 1 traffic light, 44.4ms\n",
      "Speed: 1.2ms preprocess, 44.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 48 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 45.4ms\n",
      "Speed: 1.2ms preprocess, 45.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 49 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 45.4ms\n",
      "Speed: 1.2ms preprocess, 45.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 50 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 51 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 46.8ms\n",
      "Speed: 1.3ms preprocess, 46.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 52 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 41.5ms\n",
      "Speed: 1.5ms preprocess, 41.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 53 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 39.5ms\n",
      "Speed: 1.0ms preprocess, 39.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 54 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 40.1ms\n",
      "Speed: 1.3ms preprocess, 40.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 55 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 44.3ms\n",
      "Speed: 1.2ms preprocess, 44.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 56 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 46.3ms\n",
      "Speed: 1.3ms preprocess, 46.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 57 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 46.1ms\n",
      "Speed: 1.1ms preprocess, 46.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 58 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 1 traffic light, 42.1ms\n",
      "Speed: 1.1ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 59 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 48.0ms\n",
      "Speed: 1.7ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 60 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 44.8ms\n",
      "Speed: 1.2ms preprocess, 44.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 61 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 49.5ms\n",
      "Speed: 1.4ms preprocess, 49.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 62 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 horse, 44.3ms\n",
      "Speed: 1.3ms preprocess, 44.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 63 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 47.0ms\n",
      "Speed: 1.4ms preprocess, 47.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 64 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 42.6ms\n",
      "Speed: 1.3ms preprocess, 42.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 65 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 horse, 45.2ms\n",
      "Speed: 1.8ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 66 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 horse, 45.9ms\n",
      "Speed: 1.2ms preprocess, 45.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 67 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 41.5ms\n",
      "Speed: 1.2ms preprocess, 41.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 68 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 42.7ms\n",
      "Speed: 1.2ms preprocess, 42.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 69 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 41.5ms\n",
      "Speed: 1.4ms preprocess, 41.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 70 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 44.0ms\n",
      "Speed: 1.2ms preprocess, 44.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 71 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 42.8ms\n",
      "Speed: 1.1ms preprocess, 42.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 72 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 73 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 45.2ms\n",
      "Speed: 1.1ms preprocess, 45.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 74 - Status: Standing\n",
      "\n",
      "0: 384x640 2 persons, 1 horse, 43.3ms\n",
      "Speed: 1.4ms preprocess, 43.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 75 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 42.1ms\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 76 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 41.3ms\n",
      "Speed: 1.4ms preprocess, 41.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 77 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 44.3ms\n",
      "Speed: 1.3ms preprocess, 44.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 78 - Status: Standing\n",
      "\n",
      "0: 384x640 1 person, 47.3ms\n",
      "Speed: 1.1ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 79 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 46.6ms\n",
      "Speed: 1.6ms preprocess, 46.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 80 - Status: Lying\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 43.9ms\n",
      "Speed: 1.4ms preprocess, 43.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 81 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 chair, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 82 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 38.9ms\n",
      "Speed: 1.2ms preprocess, 38.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 83 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 traffic light, 1 dog, 1 chair, 41.8ms\n",
      "Speed: 1.3ms preprocess, 41.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 84 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 chair, 46.3ms\n",
      "Speed: 1.1ms preprocess, 46.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 85 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 traffic light, 1 dog, 1 chair, 43.7ms\n",
      "Speed: 1.3ms preprocess, 43.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 86 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 cat, 1 chair, 49.9ms\n",
      "Speed: 1.2ms preprocess, 49.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 87 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 39.3ms\n",
      "Speed: 1.3ms preprocess, 39.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 88 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 chair, 40.1ms\n",
      "Speed: 1.1ms preprocess, 40.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 89 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 traffic light, 1 dog, 1 chair, 48.3ms\n",
      "Speed: 1.5ms preprocess, 48.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 90 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 traffic light, 1 dog, 1 chair, 44.9ms\n",
      "Speed: 1.6ms preprocess, 44.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 91 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 traffic light, 1 dog, 1 chair, 42.6ms\n",
      "Speed: 1.2ms preprocess, 42.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 92 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 traffic light, 1 dog, 1 chair, 43.7ms\n",
      "Speed: 1.1ms preprocess, 43.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 93 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 45.5ms\n",
      "Speed: 1.1ms preprocess, 45.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 94 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 traffic light, 1 dog, 1 chair, 42.1ms\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 95 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 traffic light, 1 dog, 1 chair, 44.6ms\n",
      "Speed: 0.9ms preprocess, 44.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 96 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 49.0ms\n",
      "Speed: 1.1ms preprocess, 49.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 97 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 traffic light, 1 dog, 1 chair, 45.8ms\n",
      "Speed: 1.2ms preprocess, 45.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 98 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 dog, 1 bottle, 1 chair, 45.0ms\n",
      "Speed: 1.2ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 99 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 cat, 1 dog, 1 chair, 42.5ms\n",
      "Speed: 1.3ms preprocess, 42.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 100 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 traffic light, 1 cat, 1 dog, 1 chair, 44.8ms\n",
      "Speed: 1.1ms preprocess, 44.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 101 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 43.9ms\n",
      "Speed: 1.3ms preprocess, 43.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 102 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 traffic light, 1 dog, 1 chair, 43.1ms\n",
      "Speed: 1.0ms preprocess, 43.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 103 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 traffic light, 1 dog, 1 chair, 41.8ms\n",
      "Speed: 1.0ms preprocess, 41.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 104 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 43.1ms\n",
      "Speed: 1.1ms preprocess, 43.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 105 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 44.2ms\n",
      "Speed: 1.0ms preprocess, 44.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 106 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 45.6ms\n",
      "Speed: 1.2ms preprocess, 45.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 107 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 42.4ms\n",
      "Speed: 1.5ms preprocess, 42.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 108 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 41.7ms\n",
      "Speed: 1.1ms preprocess, 41.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 109 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 44.4ms\n",
      "Speed: 1.1ms preprocess, 44.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 110 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 41.9ms\n",
      "Speed: 1.4ms preprocess, 41.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 111 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 42.3ms\n",
      "Speed: 1.3ms preprocess, 42.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 112 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 traffic light, 1 dog, 1 chair, 40.8ms\n",
      "Speed: 1.2ms preprocess, 40.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 113 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 42.6ms\n",
      "Speed: 1.4ms preprocess, 42.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 114 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 traffic light, 1 dog, 1 chair, 44.6ms\n",
      "Speed: 1.0ms preprocess, 44.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 115 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 44.1ms\n",
      "Speed: 1.1ms preprocess, 44.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 116 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 46.4ms\n",
      "Speed: 1.1ms preprocess, 46.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 117 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 44.8ms\n",
      "Speed: 1.1ms preprocess, 44.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 118 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 47.0ms\n",
      "Speed: 1.2ms preprocess, 47.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 119 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 43.5ms\n",
      "Speed: 1.6ms preprocess, 43.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 120 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 121 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 46.1ms\n",
      "Speed: 1.4ms preprocess, 46.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 122 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 43.6ms\n",
      "Speed: 1.6ms preprocess, 43.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 123 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 45.2ms\n",
      "Speed: 1.2ms preprocess, 45.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 124 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 42.6ms\n",
      "Speed: 1.3ms preprocess, 42.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 125 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 42.2ms\n",
      "Speed: 1.0ms preprocess, 42.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 126 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 41.9ms\n",
      "Speed: 1.2ms preprocess, 41.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 127 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 42.5ms\n",
      "Speed: 1.1ms preprocess, 42.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 128 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 42.1ms\n",
      "Speed: 1.2ms preprocess, 42.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 129 - Status: Potential Fall\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 46.7ms\n",
      "Speed: 1.1ms preprocess, 46.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 130 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 46.0ms\n",
      "Speed: 1.4ms preprocess, 46.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 131 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 44.1ms\n",
      "Speed: 1.4ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 132 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 50.0ms\n",
      "Speed: 1.1ms preprocess, 50.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 133 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 47.3ms\n",
      "Speed: 1.1ms preprocess, 47.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 134 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 45.5ms\n",
      "Speed: 1.3ms preprocess, 45.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 135 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 47.1ms\n",
      "Speed: 1.2ms preprocess, 47.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 136 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 42.0ms\n",
      "Speed: 1.3ms preprocess, 42.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 137 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 46.7ms\n",
      "Speed: 1.2ms preprocess, 46.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 138 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 44.4ms\n",
      "Speed: 1.3ms preprocess, 44.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 139 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 41.6ms\n",
      "Speed: 1.0ms preprocess, 41.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 140 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 50.9ms\n",
      "Speed: 1.0ms preprocess, 50.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 141 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 44.0ms\n",
      "Speed: 1.1ms preprocess, 44.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 142 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 47.4ms\n",
      "Speed: 1.5ms preprocess, 47.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 143 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 traffic light, 1 dog, 1 chair, 42.7ms\n",
      "Speed: 1.0ms preprocess, 42.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 144 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 41.5ms\n",
      "Speed: 1.0ms preprocess, 41.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 145 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 44.2ms\n",
      "Speed: 1.4ms preprocess, 44.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 146 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 40.7ms\n",
      "Speed: 1.0ms preprocess, 40.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 147 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 40.5ms\n",
      "Speed: 1.3ms preprocess, 40.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 148 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 48.1ms\n",
      "Speed: 1.5ms preprocess, 48.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 149 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 43.9ms\n",
      "Speed: 1.2ms preprocess, 43.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 150 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 41.1ms\n",
      "Speed: 1.2ms preprocess, 41.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 151 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 44.7ms\n",
      "Speed: 1.5ms preprocess, 44.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 152 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 43.0ms\n",
      "Speed: 1.1ms preprocess, 43.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 153 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 39.3ms\n",
      "Speed: 1.1ms preprocess, 39.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 154 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 43.4ms\n",
      "Speed: 1.3ms preprocess, 43.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 155 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 42.1ms\n",
      "Speed: 1.2ms preprocess, 42.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 156 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 44.8ms\n",
      "Speed: 1.2ms preprocess, 44.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 157 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 42.9ms\n",
      "Speed: 1.2ms preprocess, 42.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 158 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 41.8ms\n",
      "Speed: 1.3ms preprocess, 41.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 159 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 traffic light, 1 dog, 1 chair, 41.6ms\n",
      "Speed: 1.0ms preprocess, 41.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 160 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 161 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 44.4ms\n",
      "Speed: 1.2ms preprocess, 44.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 162 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 38.1ms\n",
      "Speed: 1.1ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 163 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 42.1ms\n",
      "Speed: 1.2ms preprocess, 42.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 164 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 45.5ms\n",
      "Speed: 1.1ms preprocess, 45.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 165 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 49.6ms\n",
      "Speed: 1.1ms preprocess, 49.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 166 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 43.2ms\n",
      "Speed: 1.3ms preprocess, 43.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 167 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 traffic light, 1 dog, 1 chair, 40.1ms\n",
      "Speed: 1.1ms preprocess, 40.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 168 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 44.4ms\n",
      "Speed: 1.0ms preprocess, 44.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 169 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 40.2ms\n",
      "Speed: 1.2ms preprocess, 40.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 170 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 42.0ms\n",
      "Speed: 1.1ms preprocess, 42.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 171 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 43.4ms\n",
      "Speed: 0.9ms preprocess, 43.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 172 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 45.3ms\n",
      "Speed: 1.3ms preprocess, 45.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 173 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 traffic light, 1 dog, 1 chair, 47.4ms\n",
      "Speed: 1.0ms preprocess, 47.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 174 - Status: Fall Detected!\n",
      "\n",
      "0: 384x640 1 person, 1 traffic light, 1 dog, 1 chair, 58.2ms\n",
      "Speed: 1.3ms preprocess, 58.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processing frame: 175 - Status: Fall Detected!\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "# Jupyter 환경에서 src 폴더의 모듈을 가져오기 위해 경로를 추가합니다.\n",
    "import sys\n",
    "# 경로 추가에 필요한 os 모듈을 가져옵니다.\n",
    "import os\n",
    "\n",
    "# 현재 노트북 파일의 상위 폴더(FALL-DETECTION)의 경로를 sys.path에 추가합니다.\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# 이미지 및 비디오 처리를 위해 cv2(OpenCV)를 가져옵니다.\n",
    "import cv2\n",
    "# 시간 관련 기능을 위해 time 모듈을 가져옵니다.\n",
    "import time\n",
    "# numpy를 가져와서 수치 연산에 사용합니다.\n",
    "import numpy as np\n",
    "\n",
    "# src 폴더의 핵심 클래스들을 가져옵니다.\n",
    "from src.detector import YoloDetector\n",
    "from src.pose_estimator import PoseEstimator\n",
    "from src.fall_logic import FallDetectorLogic\n",
    "\n",
    "\n",
    "# 1. 초기화 (Initialization)\n",
    "# ---\n",
    "\n",
    "# YOLO, MediaPipe, 낙상 로직 클래스의 인스턴스를 생성합니다.\n",
    "yolo_detector = YoloDetector()\n",
    "pose_estimator = PoseEstimator()\n",
    "fall_logic = FallDetectorLogic()\n",
    "\n",
    "# 비디오 파일 경로 설정. (FALL-DETECTION/data/videos/fall.mp4)\n",
    "video_path = os.path.join(os.path.abspath(os.path.join(os.getcwd(), '..')), 'data', 'videos', '03.mp4')\n",
    "\n",
    "# OpenCV를 사용하여 비디오 파일을 엽니다.\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 비디오 파일이 성공적으로 열렸는지 확인합니다.\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video file at {video_path}\")\n",
    "    # 노트북 실행을 중단합니다.\n",
    "    raise FileNotFoundError(\"Video file not found or could not be opened.\")\n",
    "\n",
    "# 프레임 수를 제한하여 디버깅 속도를 높입니다. (예: 50 프레임만 처리)\n",
    "# FRAME_LIMIT = 240\n",
    "frame_count = 0\n",
    "\n",
    "# 낙상 지표 기록을 위한 리스트를 초기화합니다.\n",
    "# 시각화 셀에서 그래프를 그리는 데 사용됩니다.\n",
    "status_history = []\n",
    "\n",
    "\n",
    "# 2. 메인 처리 루프 (Main Processing Loop)\n",
    "# ---\n",
    "\n",
    "# 비디오가 열려 있고 프레임 제한을 넘지 않은 동안 반복합니다.\n",
    "while cap.isOpened():\n",
    "    # 비디오에서 다음 프레임을 읽습니다.\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # 프레임을 제대로 읽지 못했다면 루프를 종료합니다.\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 현재 시간을 기록합니다.\n",
    "    current_time = time.time()\n",
    "    \n",
    "    # 1. YOLO를 사용하여 사람을 감지하고 바운딩 박스를 얻습니다.\n",
    "    detections = yolo_detector.detect_person(frame)\n",
    "\n",
    "    # 감지된 각 사람에 대해 반복합니다.\n",
    "    for person_data in detections:\n",
    "        bbox = person_data['bbox']\n",
    "        # 디버깅 목적으로 임시 track_id 1을 사용합니다.\n",
    "        track_id = 1 \n",
    "\n",
    "        # 2. MediaPipe를 사용하여 뼈대 랜드마크를 추정하고 프레임에 그립니다.\n",
    "        pose_landmarks = pose_estimator.estimate_pose(frame)\n",
    "        \n",
    "        # 3. 낙상 로직을 실행하여 상태를 판단합니다.\n",
    "        person_status = fall_logic.process_detection(track_id, bbox, current_time)\n",
    "\n",
    "        # 상태 기록 (디버깅 그래프 생성을 위해)\n",
    "        status_history.append({'frame': frame_count, 'status': person_status})\n",
    "\n",
    "        # 4. 시각화 및 결과 출력\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        color = (0, 255, 0)\n",
    "        if 'Fall' in person_status or 'Lying' in person_status:\n",
    "            color = (0, 0, 255) # 낙상/누움 상태는 빨간색\n",
    "\n",
    "        # 바운딩 박스를 프레임에 그립니다.\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        # 상태 텍스트를 프레임에 표시합니다.\n",
    "        cv2.putText(frame, person_status, (x1, y1 - 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "        \n",
    "    # 처리된 프레임을 시각적으로 확인합니다.\n",
    "    # if frame_count % 10 == 0:\n",
    "    print(f\"Processing frame: {frame_count} - Status: {person_status}\")\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# 3. 종료 (Finalization)\n",
    "# ---\n",
    "\n",
    "# 비디오 캡처 자원을 해제합니다.\n",
    "cap.release()\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da14a397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Status Log (First 10 entries) ---\n",
      "   frame    status\n",
      "0      0  Standing\n",
      "1      1  Standing\n",
      "2      2  Standing\n",
      "3      3  Standing\n",
      "4      4  Standing\n",
      "5      5  Standing\n",
      "6      6  Standing\n",
      "7      7  Standing\n",
      "8      8  Standing\n",
      "9      9  Standing\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 기록된 상태 히스토리를 DataFrame으로 변환합니다.\n",
    "df = pd.DataFrame(status_history)\n",
    "\n",
    "# 시간 경과에 따른 상태 변화를 시각화합니다.\n",
    "plt.figure(figsize=(15, 6))\n",
    "# 상태를 시각화하기 위해 각 상태에 숫자 값을 부여합니다.\n",
    "status_map = {'Standing': 0, 'Sitting': 1, 'Potential Fall': 2, 'Lying': 3, 'Fall Detected!': 4}\n",
    "df['status_code'] = df['status'].map(status_map)\n",
    "\n",
    "# 상태 코드 변화를 프레임 번호에 따라 그래프로 표시합니다.\n",
    "plt.plot(df['frame'], df['status_code'], marker='o', linestyle='-')\n",
    "plt.yticks(list(status_map.values()), list(status_map.keys()))\n",
    "plt.xlabel(\"Frame Number\")\n",
    "plt.ylabel(\"Fall Detection Status\")\n",
    "plt.title(\"Algorithm Status Change Over Time\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 최종적으로 기록된 상태 변화를 출력합니다.\n",
    "print(\"\\n--- Final Status Log (First 10 entries) ---\")\n",
    "print(df[['frame', 'status']].head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
